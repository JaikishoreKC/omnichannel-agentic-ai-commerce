============================= test session starts =============================
platform win32 -- Python 3.10.11, pytest-8.4.1, pluggy-1.6.0
rootdir: D:\Projects\omnichannel-agentic-commerce\backend
configfile: pytest.ini
plugins: anyio-4.9.0, asyncio-1.3.0, cov-6.2.1
asyncio: mode=strict, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 90 items

tests\unit\test_admin_activity_service.py ..                             [  2%]
tests\unit\test_auth_totp.py ...                                         [  5%]
tests\unit\test_base_agent.py .                                          [  6%]
tests\unit\test_circuit_breaker_and_classifier.py ...............        [ 23%]
tests\unit\test_guest_cart_transfer_on_login.py F                        [ 24%]
tests\unit\test_guest_checkout_guard.py .                                [ 25%]
tests\unit\test_llm_client.py FFFFFFFFFFFFFFFFFFF                        [ 46%]
tests\unit\test_metrics_collector.py .                                   [ 47%]
tests\unit\test_mongo_indexes.py ..                                      [ 50%]
tests\unit\test_perf_smoke_script.py ...                                 [ 53%]
tests\unit\test_rate_limiter.py ..                                       [ 55%]
tests\unit\test_repositories.py .............                            [ 70%]
tests\unit\test_repository_fallbacks.py ...                              [ 73%]
tests\unit\test_scripts_bootstrap_and_indexes.py .....                   [ 78%]
tests\unit\test_state_persistence_and_clients.py ....                    [ 83%]
tests\unit\test_store_state_snapshot.py .                                [ 84%]
tests\unit\test_superu_client.py .......                                 [ 92%]
tests\unit\test_voice_recovery_service.py .......                        [100%]

================================== FAILURES ===================================
___________________ test_guest_cart_is_attached_after_login ___________________

>   ???
E   assert 0 == 2

D:\Projects\omnichannel-agentic-ai-commerce\backend\tests\unit\test_guest_cart_transfer_on_login.py:37: AssertionError
___________________ test_enabled_flag_checks_provider_keys ____________________

    def test_enabled_flag_checks_provider_keys() -> None:
>       disabled = LLMClient(settings=_base_settings(llm_enabled=False))

tests\unit\test_llm_client.py:55: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_enabled': False}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': False, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_______________ test_classify_intent_returns_none_when_disabled _______________

    def test_classify_intent_returns_none_when_disabled() -> None:
>       client = LLMClient(settings=_base_settings(llm_enabled=False))

tests\unit\test_llm_client.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_enabled': False}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': False, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_____________ test_classify_intent_disabled_when_planner_enabled ______________

    def test_classify_intent_disabled_when_planner_enabled() -> None:
>       client = LLMClient(settings=_base_settings(llm_planner_enabled=True))

tests\unit\test_llm_client.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
__________ test_classify_intent_enabled_when_classifier_first_policy __________

    def test_classify_intent_enabled_when_classifier_first_policy() -> None:
        client = LLMClient(
>           settings=_base_settings(
                llm_planner_enabled=True,
                llm_decision_policy="classifier_first",
            )
        )

tests\unit\test_llm_client.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_decision_policy': 'classifier_first', 'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_decision_policy': 'classifier_first', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
________ test_classify_intent_parses_valid_json_and_clamps_confidence _________

    def test_classify_intent_parses_valid_json_and_clamps_confidence() -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_________ test_classify_intent_rejects_unsupported_or_invalid_payload _________

    def test_classify_intent_rejects_unsupported_or_invalid_payload() -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:105: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_______________ test_classify_intent_handles_wrapped_json_text ________________

    def test_classify_intent_handles_wrapped_json_text() -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:117: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
__________ test_classify_intent_handles_circuit_open_and_exceptions ___________

    def test_classify_intent_handles_circuit_open_and_exceptions() -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:128: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_______________ test_call_intent_model_rejects_unknown_provider _______________

    def test_call_intent_model_rejects_unknown_provider() -> None:
>       client = LLMClient(settings=_base_settings(llm_provider="unknown"))

tests\unit\test_llm_client.py:137: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_provider': 'unknown'}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
__________________________ test_openai_call_success ___________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026E30E4C3A0>

    def test_openai_call_success(monkeypatch: pytest.MonkeyPatch) -> None:
        captured: dict[str, Any] = {}
    
        def fake_post(url: str, **kwargs: Any) -> _DummyResponse:
            captured["url"] = url
            captured["kwargs"] = kwargs
            return _DummyResponse(
                {
                    "choices": [
                        {
                            "message": {
                                "content": '{"intent":"checkout","confidence":0.9,"entities":{}}'
                            }
                        }
                    ]
                }
            )
    
        monkeypatch.setattr(httpx, "post", fake_post)
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
___________________________ test_openai_call_errors ___________________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026E30E438E0>

    def test_openai_call_errors(monkeypatch: pytest.MonkeyPatch) -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:169: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
___________________ test_anthropic_call_success_and_errors ____________________

monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x0000026E30CD43A0>

    def test_anthropic_call_success_and_errors(monkeypatch: pytest.MonkeyPatch) -> None:
>       client = LLMClient(settings=_base_settings(llm_provider="anthropic"))

tests\unit\test_llm_client.py:188: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_provider': 'anthropic'}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
________________ test_plan_actions_parses_multi_action_payload ________________

    def test_plan_actions_parses_multi_action_payload() -> None:
>       client = LLMClient(settings=_planner_settings())

tests\unit\test_llm_client.py:229: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\unit\test_llm_client.py:52: in _planner_settings
    return _base_settings(**planner_overrides)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_intent_classifier_enabled': False, 'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': False, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
___________ test_plan_actions_returns_clarification_when_requested ____________

    def test_plan_actions_returns_clarification_when_requested() -> None:
>       client = LLMClient(settings=_planner_settings())

tests\unit\test_llm_client.py:249: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\unit\test_llm_client.py:52: in _planner_settings
    return _base_settings(**planner_overrides)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_intent_classifier_enabled': False, 'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': False, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_______ test_plan_actions_ignores_low_confidence_or_unsupported_actions _______

    def test_plan_actions_ignores_low_confidence_or_unsupported_actions() -> None:
>       client = LLMClient(settings=_planner_settings())

tests\unit\test_llm_client.py:264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\unit\test_llm_client.py:52: in _planner_settings
    return _base_settings(**planner_overrides)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_intent_classifier_enabled': False, 'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': False, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
_________________ test_plan_actions_sanitizes_unknown_params __________________

    def test_plan_actions_sanitizes_unknown_params() -> None:
>       client = LLMClient(settings=_planner_settings())

tests\unit\test_llm_client.py:283: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\unit\test_llm_client.py:52: in _planner_settings
    return _base_settings(**planner_overrides)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_intent_classifier_enabled': False, 'llm_planner_enabled': True}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': False, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
________________ test_plan_actions_respects_configured_limits _________________

    def test_plan_actions_respects_configured_limits() -> None:
>       client = LLMClient(settings=_planner_settings(llm_planner_max_actions=1, llm_planner_min_confidence=0.9))

tests\unit\test_llm_client.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\unit\test_llm_client.py:52: in _planner_settings
    return _base_settings(**planner_overrides)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_intent_classifier_enabled': False, 'llm_planner_enabled': True, 'llm_planner_max_actions': 1, 'llm_planner_min_confidence': 0.9}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': False, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
___ test_call_action_planner_model_dispatches_and_rejects_unknown_provider ____

    def test_call_action_planner_model_dispatches_and_rejects_unknown_provider() -> None:
>       openai_client = LLMClient(settings=_base_settings(llm_provider="openai"))

tests\unit\test_llm_client.py:317: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {'llm_provider': 'openai'}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
___________ test_build_action_plan_prompt_contains_allowed_actions ____________

    def test_build_action_plan_prompt_contains_allowed_actions() -> None:
>       client = LLMClient(settings=_base_settings())

tests\unit\test_llm_client.py:335: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

overrides = {}
data = {'anthropic_api_key': 'sk-ant-test', 'llm_enabled': True, 'llm_intent_classifier_enabled': True, 'llm_max_tokens': 128, ...}

    def _base_settings(**overrides: Any) -> Settings:
        data = {
            "llm_enabled": True,
            "llm_provider": "openai",
            "llm_model": "gpt-4o-mini",
            "openai_api_key": "sk-test",
            "anthropic_api_key": "sk-ant-test",
            "llm_timeout_seconds": 3.0,
            "llm_max_tokens": 128,
            "llm_intent_classifier_enabled": True,
            "llm_planner_enabled": False,
            "llm_planner_max_actions": 5,
            "llm_planner_min_confidence": 0.55,
        }
        data.update(overrides)
>       return Settings(**data)
E       TypeError: Settings.__init__() got an unexpected keyword argument 'openai_api_key'

tests\unit\test_llm_client.py:43: TypeError
=========================== short test summary info ===========================
FAILED tests/unit/test_guest_cart_transfer_on_login.py::test_guest_cart_is_attached_after_login
FAILED tests/unit/test_llm_client.py::test_enabled_flag_checks_provider_keys
FAILED tests/unit/test_llm_client.py::test_classify_intent_returns_none_when_disabled
FAILED tests/unit/test_llm_client.py::test_classify_intent_disabled_when_planner_enabled
FAILED tests/unit/test_llm_client.py::test_classify_intent_enabled_when_classifier_first_policy
FAILED tests/unit/test_llm_client.py::test_classify_intent_parses_valid_json_and_clamps_confidence
FAILED tests/unit/test_llm_client.py::test_classify_intent_rejects_unsupported_or_invalid_payload
FAILED tests/unit/test_llm_client.py::test_classify_intent_handles_wrapped_json_text
FAILED tests/unit/test_llm_client.py::test_classify_intent_handles_circuit_open_and_exceptions
FAILED tests/unit/test_llm_client.py::test_call_intent_model_rejects_unknown_provider
FAILED tests/unit/test_llm_client.py::test_openai_call_success - TypeError: S...
FAILED tests/unit/test_llm_client.py::test_openai_call_errors - TypeError: Se...
FAILED tests/unit/test_llm_client.py::test_anthropic_call_success_and_errors
FAILED tests/unit/test_llm_client.py::test_plan_actions_parses_multi_action_payload
FAILED tests/unit/test_llm_client.py::test_plan_actions_returns_clarification_when_requested
FAILED tests/unit/test_llm_client.py::test_plan_actions_ignores_low_confidence_or_unsupported_actions
FAILED tests/unit/test_llm_client.py::test_plan_actions_sanitizes_unknown_params
FAILED tests/unit/test_llm_client.py::test_plan_actions_respects_configured_limits
FAILED tests/unit/test_llm_client.py::test_call_action_planner_model_dispatches_and_rejects_unknown_provider
FAILED tests/unit/test_llm_client.py::test_build_action_plan_prompt_contains_allowed_actions
======================= 20 failed, 70 passed in 12.94s ========================
